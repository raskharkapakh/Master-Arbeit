\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{USenglish}{}
\babel@aux{ngerman}{}
\babel@aux{USenglish}{}
\citation{merino2019review}
\citation{gerstoft2016multisnapshot}
\citation{ronneberger2015u}
\citation{grumiaux2022survey}
\citation{he2018deep}
\citation{ferguson2018sound}
\citation{chakrabarty2017broadband}
\citation{perotin2018crnn}
\citation{adavanne2018direction}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{takeda2016sound}
\citation{karras2017progressive}
\citation{neekhara2019expediting}
\citation{NEURIPS2019_6804c9bc}
\citation{engel2019gansynth}
\citation{neekhara2019expediting}
\citation{NEURIPS2019_6804c9bc}
\citation{engel2019gansynth}
\citation{neekhara2019expediting}
\citation{vargas2021improved}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}State of the Art}{2}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Generation of Signal}{2}{subsection.1.1.1}\protected@file@percent }
\citation{papayiannis2019data}
\citation{ratnarajah2021fast}
\citation{bianco2020semi}
\citation{gerstoft2020parametric}
\citation{hubner2021efficient}
\citation{vera2021acoustic}
\citation{castellini2021neural}
\citation{lee2021deep}
\citation{ma2019phased}
\citation{xu2021deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Generation of Impulse Response}{3}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Generation of potential NN feature}{3}{subsection.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Other possible approaches to generate the data}{3}{subsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Aim of the thesis}{3}{section.1.2}\protected@file@percent }
\citation{gerstoft2020parametric}
\citation{welch1967use}
\citation{kujawski2022fast}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamentals}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Propagation model and the Cross Spectral Matrix}{5}{section.2.1}\protected@file@percent }
\newlabel{csm}{{2.3}{5}{Propagation model and the Cross Spectral Matrix}{equation.2.1.3}{}}
\citation{sarradj2010fast}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Eigendecomposition and Rank I Cross spectral matrix}{6}{section.2.2}\protected@file@percent }
\newlabel{eigendecomposition}{{2.5}{6}{Eigendecomposition and Rank I Cross spectral matrix}{equation.2.2.5}{}}
\newlabel{rank_I_csm}{{2.6}{6}{Eigendecomposition and Rank I Cross spectral matrix}{equation.2.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Conventional beamforming}{6}{section.2.3}\protected@file@percent }
\citation{sarradj2012three}
\citation{sarradj2010fast}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of beamforming source map, with three sources.}}{7}{figure.2.1}\protected@file@percent }
\newlabel{fig:beamforming_example}{{2.1}{7}{Example of beamforming source map, with three sources}{figure.2.1}{}}
\newlabel{autopower}{{2.8}{7}{Conventional beamforming}{equation.2.3.8}{}}
\citation{goodfellow2020generative}
\citation{radford2015unsupervised}
\citation{goodfellow2020generative}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Helmotz Number}{8}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}GAN}{8}{section.2.5}\protected@file@percent }
\citation{radford2015unsupervised}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}DCGAN}{9}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}WGAN}{9}{section.2.7}\protected@file@percent }
\citation{arjovsky2017wasserstein}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}The Earth-Mover or Wasserstein distance}{10}{subsection.2.7.1}\protected@file@percent }
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Necessary changes to turn a GAN into a WGAN}{13}{subsection.2.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}WGAN-GP}{13}{section.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}The gradient penalty}{13}{subsection.2.8.1}\protected@file@percent }
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{goodfellow2020generative}
\citation{arjovsky2017wasserstein}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Assessing performances of a WGAN or WGAN-GP compared to GAN}{14}{section.2.9}\protected@file@percent }
\newlabel{sec:assessing_perf}{{2.9}{14}{Assessing performances of a WGAN or WGAN-GP compared to GAN}{section.2.9}{}}
\citation{gerstoft2020parametric}
\citation{gerstoft2020parametric}
\citation{gerstoft2020parametric}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methods}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data}{16}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Synthetic Data}{16}{subsection.3.1.1}\protected@file@percent }
\citation{kujawski2022acoupipe}
\citation{kujawski2022acoupipe}
\citation{gerstoft2012eigenvalues}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Example of the measurement setup used, with three audio sources. Image taken from \cite  {kujawski2022acoupipe}}}{17}{figure.3.1}\protected@file@percent }
\newlabel{fig:full_measurement_setup}{{3.1}{17}{Example of the measurement setup used, with three audio sources. Image taken from \cite {kujawski2022acoupipe}}{figure.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Measurement}{17}{subsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Device used as audio source to create the measurement}}{18}{figure.3.2}\protected@file@percent }
\newlabel{fig:source}{{3.2}{18}{Device used as audio source to create the measurement}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Picture of the array of microphone used to create the real measurement}}{18}{figure.3.3}\protected@file@percent }
\newlabel{fig:microphone_array}{{3.3}{18}{Picture of the array of microphone used to create the real measurement}{figure.3.3}{}}
\citation{nain2020wgangp}
\citation{nain2020wgangp}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Comparison between Synthetic and Measured Data}{19}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Architectures}{19}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Generating Eigenvalues}{19}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Generating Scaled Eigenvalues}{19}{section*.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Levels of the eigenvalues of a synthetized CSM (blue) and of a measured CSM (orange).}}{20}{figure.3.4}\protected@file@percent }
\newlabel{fig:comparison_synthetic_measurement_data}{{3.4}{20}{Levels of the eigenvalues of a synthetized CSM (blue) and of a measured CSM (orange)}{figure.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Beamforming maps, created respectively with CSMs from the synthetic dataset and from the measurement data}}{20}{figure.3.5}\protected@file@percent }
\newlabel{fig:datasets_beamforming_example}{{3.5}{20}{Beamforming maps, created respectively with CSMs from the synthetic dataset and from the measurement data}{figure.3.5}{}}
\citation{nain2020wgangp}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Full structure of the used implementation of the WGAN-GP to generate eigenvalues.}}{21}{figure.3.6}\protected@file@percent }
\newlabel{fig:flowchart_evals_wgangp}{{3.6}{21}{Full structure of the used implementation of the WGAN-GP to generate eigenvalues}{figure.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Generating the Levels of Scaled Eigenvalues}{21}{section*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Beamforming map, created with a rank I CSM created from measurement data}}{22}{figure.3.7}\protected@file@percent }
\newlabel{fig:measurement_sample_rank_I_beamforming}{{3.7}{22}{Beamforming map, created with a rank I CSM created from measurement data}{figure.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Generating Eigenvectors}{22}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Main Eigenvector}{23}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Noise Eigenvectors}{23}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Data Augmentation}{23}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Using Generated Eigenvalues}{23}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Using Generated Main Eigenvector}{23}{subsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Histograms of the values of the scalars of the eigenvectors with different index. The eigenvector with index $63$ is the main eigenvector (two last histograms).}}{24}{figure.3.8}\protected@file@percent }
\newlabel{fig:histograms_eigenvectors}{{3.8}{24}{Histograms of the values of the scalars of the eigenvectors with different index. The eigenvector with index $63$ is the main eigenvector (two last histograms)}{figure.3.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Full structure of the used implementation of the WGAN-GP to generate eigenvectors.}}{25}{figure.3.9}\protected@file@percent }
\newlabel{fig:flowchart_evecs_wgangp}{{3.9}{25}{Full structure of the used implementation of the WGAN-GP to generate eigenvectors}{figure.3.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Parameters}{25}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{26}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Generating Eigenvalues}{26}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Generating Eigenvalues from their Scaled Values}{26}{subsection.4.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The loss functions of the critic of the WGAN-GP for eigenvalues generation, respectively while performing the initial training and while fine-tuning}}{27}{figure.4.1}\protected@file@percent }
\newlabel{fig:loss_evals_wgangp}{{4.1}{27}{The loss functions of the critic of the WGAN-GP for eigenvalues generation, respectively while performing the initial training and while fine-tuning}{figure.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The first graph shows eigenvalues of a synthetic CSM (green), eigenvalues of a measured CSM (red), eigenvalues generated with the WGAN-GP for scaled eigenvalues after the initial training (blue) and eigenvalues generated with the WGAN-GP for scaled eigenvalues after the fine-tuning (orange). The second graph displays the levels of the same eigenvalues.}}{27}{figure.4.2}\protected@file@percent }
\newlabel{fig:samples_evals_wgangp}{{4.2}{27}{The first graph shows eigenvalues of a synthetic CSM (green), eigenvalues of a measured CSM (red), eigenvalues generated with the WGAN-GP for scaled eigenvalues after the initial training (blue) and eigenvalues generated with the WGAN-GP for scaled eigenvalues after the fine-tuning (orange). The second graph displays the levels of the same eigenvalues}{figure.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The loss functions of the critic of the WGAN-GP for the levels of eigenvalues generation, respectively while performing the initial training and while fine-tuning}}{28}{figure.4.3}\protected@file@percent }
\newlabel{fig:loss_evals_dB_wgangp}{{4.3}{28}{The loss functions of the critic of the WGAN-GP for the levels of eigenvalues generation, respectively while performing the initial training and while fine-tuning}{figure.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Generating Eigenvalues from their Level Values}{28}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Data Augmentation}{28}{subsection.4.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The first graph shows eigenvalues of a synthetic CSM (green), eigenvalues of a measured CSM (red), eigenvalues generated with the WGAN-GP for level of eigenvalues after the initial training (blue) and eigenvalues generated with the WGAN-GP for level of eigenvalues after the fine-tuning (orange). The second graph displays the levels of the same eigenvalues.}}{29}{figure.4.4}\protected@file@percent }
\newlabel{fig:samples_evals_dB_wgangp}{{4.4}{29}{The first graph shows eigenvalues of a synthetic CSM (green), eigenvalues of a measured CSM (red), eigenvalues generated with the WGAN-GP for level of eigenvalues after the initial training (blue) and eigenvalues generated with the WGAN-GP for level of eigenvalues after the fine-tuning (orange). The second graph displays the levels of the same eigenvalues}{figure.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Generating Eigenvectors}{29}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Generating the Main Eigenvector}{29}{subsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The first beamforming map has been perfomed with a CSM computed with the data augemntation scheme. The second map shwos the difference between the beamforming map obtained with CSM from respectively the data augmentation dataset and the training dataset}}{30}{figure.4.5}\protected@file@percent }
\newlabel{fig:beamforming_map_data_augmentation}{{4.5}{30}{The first beamforming map has been perfomed with a CSM computed with the data augemntation scheme. The second map shwos the difference between the beamforming map obtained with CSM from respectively the data augmentation dataset and the training dataset}{figure.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The loss functions of the critic of the WGAN-GP for the main eigenvector generation, respectively while performing the initial training and while fine-tuning}}{30}{figure.4.6}\protected@file@percent }
\newlabel{fig:loss_main_evec_wgangp}{{4.6}{30}{The loss functions of the critic of the WGAN-GP for the main eigenvector generation, respectively while performing the initial training and while fine-tuning}{figure.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces The first beamforming map has been perfomed with a Rank I CSM computed with a generated main eigenvector. The second map shows the difference between the beamforming map obtained with Rank I CSM computed respectively with a generated main eigenvector and a main eigenvector from the dataset.}}{31}{figure.4.7}\protected@file@percent }
\newlabel{fig:beamforming_map_main_evec_wgangp}{{4.7}{31}{The first beamforming map has been perfomed with a Rank I CSM computed with a generated main eigenvector. The second map shows the difference between the beamforming map obtained with Rank I CSM computed respectively with a generated main eigenvector and a main eigenvector from the dataset}{figure.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Generating All the Eigenvectors}{31}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Data Augmentation}{31}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussions}{32}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Generating Eigenvalues}{32}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Generating Eigenvalues from their Scaled Values}{32}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Generating Eigenvalues from their Level Values}{32}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Data Augmentation}{32}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Generating Eigenvectors}{33}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Generating the Main Eigenvector}{33}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Generating All the Eigenvectors}{33}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Data Augmentation}{33}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}General}{33}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{35}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Future Works}{36}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Architectures of the Different Networks}{37}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate eigenvalues. Total params: 756,288, Trainable params: 755,776, Non-trainable params: 512}}{37}{table.A.1}\protected@file@percent }
\newlabel{tab:evals_generator_WGANGP_architecture}{{A.1}{37}{Architecture of the generator used in the WGAN-GP to generate eigenvalues. Total params: 756,288, Trainable params: 755,776, Non-trainable params: 512}{table.A.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate eigenvalues. Total params: 164,865, Trainable params: 164,865, Non-trainable params: 0}}{38}{table.A.2}\protected@file@percent }
\newlabel{tab:evals_critic_WGANGP_architecture}{{A.2}{38}{Architecture of the critic used in the WGAN-GP to generate eigenvalues. Total params: 164,865, Trainable params: 164,865, Non-trainable params: 0}{table.A.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate eigenvalues from their level values. Total params: 756,288, Trainable params: 755,776, Non-trainable params: 512}}{38}{table.A.3}\protected@file@percent }
\newlabel{tab:evals_dB_generator_WGANGP_architecture}{{A.3}{38}{Architecture of the generator used in the WGAN-GP to generate eigenvalues from their level values. Total params: 756,288, Trainable params: 755,776, Non-trainable params: 512}{table.A.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate eigenvalues from their level values. Total params: 164,865, Trainable params: 164,865, Non-trainable params: 0}}{38}{table.A.4}\protected@file@percent }
\newlabel{tab:evals_dB_critic_WGANGP_architecture}{{A.4}{38}{Architecture of the critic used in the WGAN-GP to generate eigenvalues from their level values. Total params: 164,865, Trainable params: 164,865, Non-trainable params: 0}{table.A.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.5}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate the main eigenvector. Total params: 821,888, Trainable params: 821,376, Non-trainable params: 512}}{39}{table.A.5}\protected@file@percent }
\newlabel{tab:main_evec_generator_WGANGP_architecture}{{A.5}{39}{Architecture of the generator used in the WGAN-GP to generate the main eigenvector. Total params: 821,888, Trainable params: 821,376, Non-trainable params: 512}{table.A.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.6}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate the main eigenvector. Total params: 197,633, Trainable params: 197,633, Non-trainable params: 0}}{39}{table.A.6}\protected@file@percent }
\newlabel{tab:main_evec_critic_WGANGP_architecture}{{A.6}{39}{Architecture of the critic used in the WGAN-GP to generate the main eigenvector. Total params: 197,633, Trainable params: 197,633, Non-trainable params: 0}{table.A.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.7}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate the noise eigenvectors. Total params: 37,520,384, Trainable params: 37,519,872, Non-trainable params: 512}}{39}{table.A.7}\protected@file@percent }
\newlabel{tab:noise_evecs_generator_WGANGP_architecture}{{A.7}{39}{Architecture of the generator used in the WGAN-GP to generate the noise eigenvectors. Total params: 37,520,384, Trainable params: 37,519,872, Non-trainable params: 512}{table.A.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.8}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate the noise eigenvectors. Total params: 35,263,489, Trainable params: 35,263,489, Non-trainable params: 0}}{40}{table.A.8}\protected@file@percent }
\newlabel{tab:noise_evecs_critic_WGANGP_architecture}{{A.8}{40}{Architecture of the critic used in the WGAN-GP to generate the noise eigenvectors. Total params: 35,263,489, Trainable params: 35,263,489, Non-trainable params: 0}{table.A.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.9}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate snapshots used for creating an approximated CSM. Total params: 986,632, Trainable params: 977,796, Non-trainable params: 8,836}}{40}{table.A.9}\protected@file@percent }
\newlabel{tab:snapshots_generator_WGANGP_architecture}{{A.9}{40}{Architecture of the generator used in the WGAN-GP to generate snapshots used for creating an approximated CSM. Total params: 986,632, Trainable params: 977,796, Non-trainable params: 8,836}{table.A.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.10}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate snapshots used for creating an approximated CSM. Total params: 4,317,761, Trainable params: 4,317,761, Non-trainable params: 0}}{41}{table.A.10}\protected@file@percent }
\newlabel{tab:snapshots_critic_WGANGP_architecture}{{A.10}{41}{Architecture of the critic used in the WGAN-GP to generate snapshots used for creating an approximated CSM. Total params: 4,317,761, Trainable params: 4,317,761, Non-trainable params: 0}{table.A.10}{}}
\bibstyle{IEEEtran}
\bibdata{./resources/IEEEabrv,./bibliography}
\bibcite{merino2019review}{1}
\bibcite{gerstoft2016multisnapshot}{2}
\bibcite{ronneberger2015u}{3}
\bibcite{grumiaux2022survey}{4}
\bibcite{he2018deep}{5}
\bibcite{ferguson2018sound}{6}
\bibcite{chakrabarty2017broadband}{7}
\bibcite{perotin2018crnn}{8}
\bibcite{adavanne2018direction}{9}
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }Bibliography}{43}{section*.9}\protected@file@percent }
\bibcite{takeda2016sound}{10}
\bibcite{karras2017progressive}{11}
\bibcite{neekhara2019expediting}{12}
\bibcite{NEURIPS2019_6804c9bc}{13}
\bibcite{engel2019gansynth}{14}
\bibcite{vargas2021improved}{15}
\bibcite{papayiannis2019data}{16}
\bibcite{ratnarajah2021fast}{17}
\bibcite{bianco2020semi}{18}
\bibcite{gerstoft2020parametric}{19}
\bibcite{hubner2021efficient}{20}
\bibcite{vera2021acoustic}{21}
\bibcite{castellini2021neural}{22}
\bibcite{lee2021deep}{23}
\bibcite{ma2019phased}{24}
\bibcite{xu2021deep}{25}
\bibcite{welch1967use}{26}
\bibcite{kujawski2022fast}{27}
\bibcite{sarradj2010fast}{28}
\bibcite{sarradj2012three}{29}
\bibcite{goodfellow2020generative}{30}
\bibcite{radford2015unsupervised}{31}
\bibcite{arjovsky2017wasserstein}{32}
\bibcite{DBLP:journals/corr/GulrajaniAADC17}{33}
\bibcite{kujawski2022acoupipe}{34}
\bibcite{gerstoft2012eigenvalues}{35}
\bibcite{nain2020wgangp}{36}
\citation{kujawski2022acoupipe}
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }List of Figures}{47}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }List of Tables}{49}{section*.13}\protected@file@percent }
\gdef \@abspage@last{57}
