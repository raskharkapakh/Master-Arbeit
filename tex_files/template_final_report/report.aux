\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{USenglish}{}
\citation{merino2019review}
\citation{gerstoft2016multisnapshot}
\citation{ronneberger2015u}
\citation{grumiaux2022survey}
\citation{he2018deep}
\citation{ferguson2018sound}
\citation{chakrabarty2017broadband}
\citation{perotin2018crnn}
\citation{adavanne2018direction}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{takeda2016sound}
\citation{karras2017progressive}
\citation{neekhara2019expediting}
\citation{NEURIPS2019_6804c9bc}
\citation{engel2019gansynth}
\citation{neekhara2019expediting}
\citation{NEURIPS2019_6804c9bc}
\citation{engel2019gansynth}
\citation{neekhara2019expediting}
\citation{vargas2021improved}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}State of the Art}{2}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Generation of Signal}{2}{subsection.1.1.1}\protected@file@percent }
\citation{papayiannis2019data}
\citation{ratnarajah2021fast}
\citation{bianco2020semi}
\citation{gerstoft2020parametric}
\citation{hubner2021efficient}
\citation{vera2021acoustic}
\citation{castellini2021neural}
\citation{lee2021deep}
\citation{ma2019phased}
\citation{xu2021deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Generation of Impulse Response}{3}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Generation of potential NN feature}{3}{subsection.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.4}Other possible approaches to generate the data}{3}{subsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Aim of the thesis}{3}{section.1.2}\protected@file@percent }
\citation{gerstoft2020parametric}
\citation{welch1967use}
\citation{kujawski2022fast}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamentals}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Propagation model and the Cross Spectral Matrix}{5}{section.2.1}\protected@file@percent }
\newlabel{csm}{{2.3}{5}{Propagation model and the Cross Spectral Matrix}{equation.2.1.3}{}}
\citation{sarradj2010fast}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Eigendecomposition and Rank I Cross spectral matrix}{6}{section.2.2}\protected@file@percent }
\newlabel{eigendecomposition}{{2.5}{6}{Eigendecomposition and Rank I Cross spectral matrix}{equation.2.2.5}{}}
\newlabel{rank_I_csm}{{2.6}{6}{Eigendecomposition and Rank I Cross spectral matrix}{equation.2.2.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Conventional beamforming}{6}{section.2.3}\protected@file@percent }
\citation{sarradj2012three}
\citation{sarradj2010fast}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of beamforming source map, with three sources.\relax }}{7}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:beamforming_example}{{2.1}{7}{Example of beamforming source map, with three sources.\relax }{figure.caption.3}{}}
\newlabel{autopower}{{2.8}{7}{Conventional beamforming}{equation.2.3.8}{}}
\citation{goodfellow2020generative}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Helmotz Number}{8}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}GAN}{8}{section.2.5}\protected@file@percent }
\citation{arjovsky2017wasserstein}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}WGAN}{9}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}The Earth-Mover or Wasserstein distance}{9}{subsection.2.6.1}\protected@file@percent }
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Necessary changes to turn a GAN into a WGAN}{12}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}WGAN-GP}{12}{section.2.7}\protected@file@percent }
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{goodfellow2020generative}
\citation{arjovsky2017wasserstein}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}The gradient penalty}{13}{subsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Assessing performances of a WGAN or WGAN-GP compared to GAN}{13}{section.2.8}\protected@file@percent }
\newlabel{sec:assessing_perf}{{2.8}{13}{Assessing performances of a WGAN or WGAN-GP compared to GAN}{section.2.8}{}}
\citation{gerstoft2020parametric}
\citation{gerstoft2020parametric}
\citation{gerstoft2020parametric}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methods}{14}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data}{15}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Synthetic Data}{15}{subsection.3.1.1}\protected@file@percent }
\citation{kujawski2022acoupipe}
\citation{kujawski2022acoupipe}
\citation{gerstoft2012eigenvalues}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Measurement}{16}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Comparison between Synthetic and Measured Data}{16}{subsection.3.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Example of the measurement setup used, with three audio sources. This is image is only for illustration purposes. In the actual performed measurement, there was only one audio source. Moreover, the dimension showed in the picture are for an aperture size of 1m, whereas in the actual performed measurement, the aperture size was of 1.46m. This means that in the actual setup every dimension were actually 1.46 times bigger than in the image. This image is taken from \cite  {kujawski2022acoupipe}\relax }}{17}{figure.caption.4}\protected@file@percent }
\newlabel{fig:full_measurement_setup}{{3.1}{17}{Example of the measurement setup used, with three audio sources. This is image is only for illustration purposes. In the actual performed measurement, there was only one audio source. Moreover, the dimension showed in the picture are for an aperture size of 1m, whereas in the actual performed measurement, the aperture size was of 1.46m. This means that in the actual setup every dimension were actually 1.46 times bigger than in the image. This image is taken from \cite {kujawski2022acoupipe}\relax }{figure.caption.4}{}}
\citation{nain2020wgangp}
\citation{nain2020wgangp}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Device used as audio source to create the measurement\relax }}{18}{figure.caption.5}\protected@file@percent }
\newlabel{fig:source}{{3.2}{18}{Device used as audio source to create the measurement\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Picture of the array of microphone used to create the real measurement\relax }}{18}{figure.caption.5}\protected@file@percent }
\newlabel{fig:microphone_array}{{3.3}{18}{Picture of the array of microphone used to create the real measurement\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Architectures}{18}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Generating Eigenvalues}{18}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Generating Scaled Eigenvalues}{18}{section*.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Levels of the eigenvalues of a synthesized CSM (blue) and of a measured CSM (orange).\relax }}{19}{figure.caption.6}\protected@file@percent }
\newlabel{fig:comparison_synthetic_measurement_data}{{3.4}{19}{Levels of the eigenvalues of a synthesized CSM (blue) and of a measured CSM (orange).\relax }{figure.caption.6}{}}
\newlabel{fig:datasets_beamforming_example_synthetic}{{3.5a}{19}{CSM from synthetic dataset\relax }{figure.caption.7}{}}
\newlabel{sub@fig:datasets_beamforming_example_synthetic}{{a}{19}{CSM from synthetic dataset\relax }{figure.caption.7}{}}
\newlabel{fig:datasets_beamforming_example_measurement}{{3.5b}{19}{CSM from measurement dataset\relax }{figure.caption.7}{}}
\newlabel{sub@fig:datasets_beamforming_example_measurement}{{b}{19}{CSM from measurement dataset\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Beamforming maps, created respectively with CSM from the synthetic dataset and from the measurement data.\relax }}{19}{figure.caption.7}\protected@file@percent }
\newlabel{fig:datasets_beamforming_example}{{3.5}{19}{Beamforming maps, created respectively with CSM from the synthetic dataset and from the measurement data.\relax }{figure.caption.7}{}}
\citation{nain2020wgangp}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Full structure of the implementation used in the WGAN-GP to generate eigenvalues or eigenvectors. The eigenvalues are being scaled before being fed to the generator, while the eigenvectors are being normalized.\relax }}{20}{figure.caption.9}\protected@file@percent }
\newlabel{fig:flowchart_wgangp}{{3.6}{20}{Full structure of the implementation used in the WGAN-GP to generate eigenvalues or eigenvectors. The eigenvalues are being scaled before being fed to the generator, while the eigenvectors are being normalized.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Generating the Levels of Scaled Eigenvalues}{20}{section*.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Beamforming map, created with a rank I CSM created from measurement data\relax }}{21}{figure.caption.11}\protected@file@percent }
\newlabel{fig:measurement_sample_rank_I_beamforming}{{3.7}{21}{Beamforming map, created with a rank I CSM created from measurement data\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Generating Eigenvectors}{21}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Main Eigenvector}{21}{section*.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Histograms of the values of the scalars of the eigenvectors with different index. The eigenvector with index $63$ is the main eigenvector (two last histograms).\relax }}{22}{figure.caption.12}\protected@file@percent }
\newlabel{fig:histograms_eigenvectors}{{3.8}{22}{Histograms of the values of the scalars of the eigenvectors with different index. The eigenvector with index $63$ is the main eigenvector (two last histograms).\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Data Augmentation}{23}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Using Generated Eigenvalues}{23}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Using Generated Main Eigenvector}{23}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Parameters}{23}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{25}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Generating Eigenvalues}{25}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Generating Eigenvalues from their Scaled Values}{25}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Generating Eigenvalues from their Level Values}{25}{subsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The loss functions of the critic of the WGAN-GP for eigenvalues generation, respectively while performing the initial training and while fine-tuning\relax }}{26}{figure.caption.14}\protected@file@percent }
\newlabel{fig:loss_evals_wgangp}{{4.1}{26}{The loss functions of the critic of the WGAN-GP for eigenvalues generation, respectively while performing the initial training and while fine-tuning\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces This graph shows the level of eigenvalues of a synthetic CSM (green), level of eigenvalues of a measured CSM (red), level of eigenvalues generated with the WGAN-GP for scaled eigenvalues after the initial training (blue) and level of eigenvalues generated with the WGAN-GP for scaled eigenvalues after the fine-tuning (orange).\relax }}{26}{figure.caption.15}\protected@file@percent }
\newlabel{fig:samples_evals_wgangp}{{4.2}{26}{This graph shows the level of eigenvalues of a synthetic CSM (green), level of eigenvalues of a measured CSM (red), level of eigenvalues generated with the WGAN-GP for scaled eigenvalues after the initial training (blue) and level of eigenvalues generated with the WGAN-GP for scaled eigenvalues after the fine-tuning (orange).\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The loss functions of the critic of the WGAN-GP for the levels of eigenvalues generation, respectively while performing the initial training and while fine-tuning\relax }}{27}{figure.caption.16}\protected@file@percent }
\newlabel{fig:loss_evals_dB_wgangp}{{4.3}{27}{The loss functions of the critic of the WGAN-GP for the levels of eigenvalues generation, respectively while performing the initial training and while fine-tuning\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Data Augmentation}{27}{subsection.4.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The first graph shows levels of eigenvalues of a synthetic CSM (green), levels of eigenvalues of a measured CSM (red), levels of eigenvalues generated with the WGAN-GP for level of eigenvalues after the initial training (blue) and levels of eigenvalues generated with the WGAN-GP for level of eigenvalues after the fine-tuning (orange).\relax }}{28}{figure.caption.17}\protected@file@percent }
\newlabel{fig:samples_evals_dB_wgangp}{{4.4}{28}{The first graph shows levels of eigenvalues of a synthetic CSM (green), levels of eigenvalues of a measured CSM (red), levels of eigenvalues generated with the WGAN-GP for level of eigenvalues after the initial training (blue) and levels of eigenvalues generated with the WGAN-GP for level of eigenvalues after the fine-tuning (orange).\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces In orange are displayed the level eigenvalues of the measurement CSM. In blue, the average (bold), the 5\% and 95\%percentiles (dotted) of generated level of eigenvalues are displayed. In gray are displayed examples of eigenvalues' levels coming from other measurements not used for training.\relax }}{28}{figure.caption.18}\protected@file@percent }
\newlabel{fig:outliers_evals_dB_wgangp}{{4.5}{28}{In orange are displayed the level eigenvalues of the measurement CSM. In blue, the average (bold), the 5\% and 95\%percentiles (dotted) of generated level of eigenvalues are displayed. In gray are displayed examples of eigenvalues' levels coming from other measurements not used for training.\relax }{figure.caption.18}{}}
\newlabel{fig:data_augmentation_evals_synthetic}{{4.6a}{29}{CSM from synthetic dataset\relax }{figure.caption.19}{}}
\newlabel{sub@fig:data_augmentation_evals_synthetic}{{a}{29}{CSM from synthetic dataset\relax }{figure.caption.19}{}}
\newlabel{fig:data_augmentation_evals_measurement}{{4.6b}{29}{CSM from measurement dataset\relax }{figure.caption.19}{}}
\newlabel{sub@fig:data_augmentation_evals_measurement}{{b}{29}{CSM from measurement dataset\relax }{figure.caption.19}{}}
\newlabel{fig:data_augmentation_evals_augmented_csm}{{4.6c}{29}{CSM Augmented with generated eigenvalues.\relax }{figure.caption.19}{}}
\newlabel{sub@fig:data_augmentation_evals_augmented_csm}{{c}{29}{CSM Augmented with generated eigenvalues.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Three beamforming maps obtained from synthetic CSM, measured CSM and CSM augmented with generated eigenvalues\relax }}{29}{figure.caption.19}\protected@file@percent }
\newlabel{fig:data_augmentation_evals}{{4.6}{29}{Three beamforming maps obtained from synthetic CSM, measured CSM and CSM augmented with generated eigenvalues\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces The loss functions of the critic of the WGAN-GP for the main eigenvector generation, respectively while performing the initial training and while fine-tuning\relax }}{30}{figure.caption.20}\protected@file@percent }
\newlabel{fig:loss_main_evec_wgangp}{{4.7}{30}{The loss functions of the critic of the WGAN-GP for the main eigenvector generation, respectively while performing the initial training and while fine-tuning\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Generating Eigenvectors}{30}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Generating the Main Eigenvector}{30}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Data Augmentation}{30}{subsection.4.2.2}\protected@file@percent }
\newlabel{fig:beamforming_map_main_evec_wgangp_generated}{{4.8a}{31}{Generated Rank I CSM\relax }{figure.caption.21}{}}
\newlabel{sub@fig:beamforming_map_main_evec_wgangp_generated}{{a}{31}{Generated Rank I CSM\relax }{figure.caption.21}{}}
\newlabel{fig:beamforming_map_main_evec_wgangp_difference}{{4.8b}{31}{Difference\relax }{figure.caption.21}{}}
\newlabel{sub@fig:beamforming_map_main_evec_wgangp_difference}{{b}{31}{Difference\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces The first beamforming map has been perfomed with a Rank I CSM computed with a generated main eigenvector. The second map shows the difference between the beamforming map obtained with Rank I CSM computed respectively with a generated main eigenvector and a main eigenvector from the dataset.\relax }}{31}{figure.caption.21}\protected@file@percent }
\newlabel{fig:beamforming_map_main_evec_wgangp}{{4.8}{31}{The first beamforming map has been perfomed with a Rank I CSM computed with a generated main eigenvector. The second map shows the difference between the beamforming map obtained with Rank I CSM computed respectively with a generated main eigenvector and a main eigenvector from the dataset.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Beamforming map resulting from a rank I CSM, computed from a generated main eigenvector with the lowest critic score out of 10000 generated main eigenvector.\relax }}{31}{figure.caption.22}\protected@file@percent }
\newlabel{fig:outliers_main_evec}{{4.9}{31}{Beamforming map resulting from a rank I CSM, computed from a generated main eigenvector with the lowest critic score out of 10000 generated main eigenvector.\relax }{figure.caption.22}{}}
\newlabel{fig:data_augmentation_evecs_synthetic}{{4.10a}{32}{CSM from synthetic dataset\relax }{figure.caption.23}{}}
\newlabel{sub@fig:data_augmentation_evecs_synthetic}{{a}{32}{CSM from synthetic dataset\relax }{figure.caption.23}{}}
\newlabel{fig:data_augmentation_evecs_measurement}{{4.10b}{32}{CSM from measurement dataset\relax }{figure.caption.23}{}}
\newlabel{sub@fig:data_augmentation_evecs_measurement}{{b}{32}{CSM from measurement dataset\relax }{figure.caption.23}{}}
\newlabel{fig:data_augmentation_evecs_augmented_csm}{{4.10c}{32}{CSM Augmented From Main Eigenvector\relax }{figure.caption.23}{}}
\newlabel{sub@fig:data_augmentation_evecs_augmented_csm}{{c}{32}{CSM Augmented From Main Eigenvector\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Three beamforming maps obtained from synthetic CSM, measured CSM and CSM augmented with generated main eigenvector\relax }}{32}{figure.caption.23}\protected@file@percent }
\newlabel{fig:data_augmentation_evecs}{{4.10}{32}{Three beamforming maps obtained from synthetic CSM, measured CSM and CSM augmented with generated main eigenvector\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussions}{33}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Generating Eigenvalues}{33}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Generating Eigenvalues from their Scaled Values}{33}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Generating Eigenvalues from their Level Values}{33}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Data Augmentation}{34}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Generating Eigenvectors}{34}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Generating the Main Eigenvector}{34}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Data Augmentation}{34}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}General}{34}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{36}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Future Works}{37}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Architectures of the Different Networks}{39}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate eigenvalues. Total parameters: 756,288, Trainable parameters: 755,776, Non-trainable parameters: 512\relax }}{40}{table.caption.24}\protected@file@percent }
\newlabel{tab:evals_generator_WGANGP_architecture}{{A.1}{40}{Architecture of the generator used in the WGAN-GP to generate eigenvalues. Total parameters: 756,288, Trainable parameters: 755,776, Non-trainable parameters: 512\relax }{table.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate eigenvalues. Total parameters: 164,865, Trainable parameters: 164,865, Non-trainable parameters: 0\relax }}{40}{table.caption.25}\protected@file@percent }
\newlabel{tab:evals_critic_WGANGP_architecture}{{A.2}{40}{Architecture of the critic used in the WGAN-GP to generate eigenvalues. Total parameters: 164,865, Trainable parameters: 164,865, Non-trainable parameters: 0\relax }{table.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate eigenvalues from their level values. Total parameters: 756,288, Trainable parameters: 755,776, Non-trainable parameters: 512\relax }}{40}{table.caption.26}\protected@file@percent }
\newlabel{tab:evals_dB_generator_WGANGP_architecture}{{A.3}{40}{Architecture of the generator used in the WGAN-GP to generate eigenvalues from their level values. Total parameters: 756,288, Trainable parameters: 755,776, Non-trainable parameters: 512\relax }{table.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate eigenvalues from their level values. Total parameters: 164,865, Trainable parameters: 164,865, Non-trainable parameters: 0\relax }}{41}{table.caption.27}\protected@file@percent }
\newlabel{tab:evals_dB_critic_WGANGP_architecture}{{A.4}{41}{Architecture of the critic used in the WGAN-GP to generate eigenvalues from their level values. Total parameters: 164,865, Trainable parameters: 164,865, Non-trainable parameters: 0\relax }{table.caption.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.5}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate the main eigenvector. Total parameters: 821,888, Trainable parameters: 821,376, Non-trainable parameters: 512\relax }}{41}{table.caption.28}\protected@file@percent }
\newlabel{tab:main_evec_generator_WGANGP_architecture}{{A.5}{41}{Architecture of the generator used in the WGAN-GP to generate the main eigenvector. Total parameters: 821,888, Trainable parameters: 821,376, Non-trainable parameters: 512\relax }{table.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.6}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate the main eigenvector. Total parameters: 197,633, Trainable parameters: 197,633, Non-trainable parameters: 0\relax }}{41}{table.caption.29}\protected@file@percent }
\newlabel{tab:main_evec_critic_WGANGP_architecture}{{A.6}{41}{Architecture of the critic used in the WGAN-GP to generate the main eigenvector. Total parameters: 197,633, Trainable parameters: 197,633, Non-trainable parameters: 0\relax }{table.caption.29}{}}
\bibstyle{IEEEtran}
\bibdata{./resources/IEEEabrv,./bibliography}
\bibcite{merino2019review}{1}
\bibcite{gerstoft2016multisnapshot}{2}
\bibcite{ronneberger2015u}{3}
\bibcite{grumiaux2022survey}{4}
\bibcite{he2018deep}{5}
\bibcite{ferguson2018sound}{6}
\bibcite{chakrabarty2017broadband}{7}
\bibcite{perotin2018crnn}{8}
\bibcite{adavanne2018direction}{9}
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }Bibliography}{43}{section*.30}\protected@file@percent }
\bibcite{takeda2016sound}{10}
\bibcite{karras2017progressive}{11}
\bibcite{neekhara2019expediting}{12}
\bibcite{NEURIPS2019_6804c9bc}{13}
\bibcite{engel2019gansynth}{14}
\bibcite{vargas2021improved}{15}
\bibcite{papayiannis2019data}{16}
\bibcite{ratnarajah2021fast}{17}
\bibcite{bianco2020semi}{18}
\bibcite{gerstoft2020parametric}{19}
\bibcite{hubner2021efficient}{20}
\bibcite{vera2021acoustic}{21}
\bibcite{castellini2021neural}{22}
\bibcite{lee2021deep}{23}
\bibcite{ma2019phased}{24}
\bibcite{xu2021deep}{25}
\bibcite{welch1967use}{26}
\bibcite{kujawski2022fast}{27}
\bibcite{sarradj2010fast}{28}
\bibcite{sarradj2012three}{29}
\bibcite{goodfellow2020generative}{30}
\bibcite{arjovsky2017wasserstein}{31}
\bibcite{DBLP:journals/corr/GulrajaniAADC17}{32}
\bibcite{kujawski2022acoupipe}{33}
\bibcite{gerstoft2012eigenvalues}{34}
\bibcite{nain2020wgangp}{35}
\citation{kujawski2022acoupipe}
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }List of Figures}{47}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }List of Tables}{49}{section*.34}\protected@file@percent }
\gdef \@abspage@last{57}
