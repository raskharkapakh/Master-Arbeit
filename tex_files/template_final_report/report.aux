\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{USenglish}{}
\babel@aux{ngerman}{}
\babel@aux{USenglish}{}
\citation{merino2019review}
\citation{gerstoft2016multisnapshot}
\citation{ronneberger2015u}
\citation{grumiaux2022survey}
\citation{he2018deep}
\citation{ferguson2018sound}
\citation{chakrabarty2017broadband}
\citation{perotin2018crnn}
\citation{adavanne2018direction}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}\protected@file@percent }
\citation{takeda2016sound}
\citation{karras2017progressive}
\citation{neekhara2019expediting}
\citation{NEURIPS2019_6804c9bc}
\citation{engel2019gansynth}
\citation{neekhara2019expediting}
\citation{NEURIPS2019_6804c9bc}
\citation{engel2019gansynth}
\citation{neekhara2019expediting}
\citation{vargas2021improved}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}State of the Art}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Generation of Signal}{2}{subsection.1.2.1}\protected@file@percent }
\citation{papayiannis2019data}
\citation{ratnarajah2021fast}
\citation{bianco2020semi}
\citation{gerstoft2020parametric}
\citation{hubner2021efficient}
\citation{vera2021acoustic}
\citation{gerstoft2020parametric}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Generation of Impulse Response}{3}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Generation of potential NN feature}{3}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Other possible approaches to generate the data}{3}{subsection.1.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.5}Take-away of the literature survey}{3}{subsection.1.2.5}\protected@file@percent }
\citation{welch1967use}
\citation{sarradj2010fast}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Fundamentals}{4}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Propagation model and the Cross Spectral Matrix}{4}{subsection.1.3.1}\protected@file@percent }
\newlabel{csm}{{1.3}{4}{Propagation model and the Cross Spectral Matrix}{equation.1.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Eigendecomposition and Rank I Cross spectral matrix}{4}{subsection.1.3.2}\protected@file@percent }
\newlabel{eigendecomposition}{{1.4}{4}{Eigendecomposition and Rank I Cross spectral matrix}{equation.1.3.4}{}}
\citation{sarradj2012three}
\citation{sarradj2010fast}
\newlabel{rank_I_csm}{{1.5}{5}{Eigendecomposition and Rank I Cross spectral matrix}{equation.1.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Conventional beamforming}{5}{subsection.1.3.3}\protected@file@percent }
\newlabel{autopower}{{1.7}{5}{Conventional beamforming}{equation.1.3.7}{}}
\citation{goodfellow2020generative}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Example of beamforming source map, with three sources.}}{6}{figure.1.1}\protected@file@percent }
\newlabel{fig:beamforming_example}{{1.1}{6}{Example of beamforming source map, with three sources}{figure.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}GAN}{6}{subsection.1.3.4}\protected@file@percent }
\citation{radford2015unsupervised}
\citation{goodfellow2020generative}
\citation{radford2015unsupervised}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.5}DCGAN}{7}{subsection.1.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.6}WGAN}{7}{subsection.1.3.6}\protected@file@percent }
\citation{arjovsky2017wasserstein}
\@writefile{toc}{\contentsline {subsubsection}{The Earth-Mover or Wasserstein distance}{8}{section*.5}\protected@file@percent }
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{arjovsky2017wasserstein}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\@writefile{toc}{\contentsline {subsubsection}{Necessary changes to turn a GAN into a WGAN}{11}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.7}WGAN-GP}{11}{subsection.1.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The gradient penalty}{11}{section*.7}\protected@file@percent }
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\citation{goodfellow2020generative}
\citation{arjovsky2017wasserstein}
\citation{DBLP:journals/corr/GulrajaniAADC17}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.8}Assessing performances of a WGAN or WGAN-GP compared to GAN}{12}{subsection.1.3.8}\protected@file@percent }
\citation{castellini2021neural}
\citation{lee2021deep}
\citation{ma2019phased}
\citation{xu2021deep}
\citation{kujawski2022fast}
\citation{gerstoft2020parametric}
\citation{gerstoft2020parametric}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Methods}{13}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{gerstoft2012eigenvalues}
\citation{gerstoft2012eigenvalues}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of the measurement setup used, with three audio sources. \textbf  {I took this figure as a screenshot from the literature review. Should I cite where it is coming from and if so could you provide me with the source ?}}}{14}{figure.2.1}\protected@file@percent }
\newlabel{fig:full_measurement_setup}{{2.1}{14}{Example of the measurement setup used, with three audio sources. \textbf {I took this figure as a screenshot from the literature review. Should I cite where it is coming from and if so could you provide me with the source ?}}{figure.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Data}{14}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Measurement}{14}{section*.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Device used as audio source to create the measurement}}{15}{figure.2.2}\protected@file@percent }
\newlabel{fig:source}{{2.2}{15}{Device used as audio source to create the measurement}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Picture of the array of microphone used to create the real measurement}}{15}{figure.2.3}\protected@file@percent }
\newlabel{fig:microphone_array}{{2.3}{15}{Picture of the array of microphone used to create the real measurement}{figure.2.3}{}}
\citation{nain2020wgangp}
\@writefile{toc}{\contentsline {subsubsection}{Synthetic Data}{16}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Comparison between Synthetic and Measured Data}{16}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The Datasets Used}{16}{section*.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Levels of the eigenvalues of a synthetized CSM (blue) and of a measured CSM (orange).}}{17}{figure.2.4}\protected@file@percent }
\newlabel{fig:comparison_synthetic_measurement_data}{{2.4}{17}{Levels of the eigenvalues of a synthetized CSM (blue) and of a measured CSM (orange)}{figure.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Beamforming maps, created respectively with CSMs from the synthetic dataset and from the measurement data}}{17}{figure.2.5}\protected@file@percent }
\newlabel{fig:datasets_beamforming_example}{{2.5}{17}{Beamforming maps, created respectively with CSMs from the synthetic dataset and from the measurement data}{figure.2.5}{}}
\citation{nain2020wgangp}
\citation{nain2020wgangp}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Architectures}{18}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Generating Scaled Eigenvalues}{18}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Generating the Levels of Scaled Eigenvalues}{18}{section*.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Full structure of the used implementation of the WGAN-GP to generate eigenvalues.}}{19}{figure.2.6}\protected@file@percent }
\newlabel{fig:flowchart_evals_wgangp}{{2.6}{19}{Full structure of the used implementation of the WGAN-GP to generate eigenvalues}{figure.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Generating Eigenvectors}{19}{subsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Beamforming map, created with a rank I CSM created from measurement data}}{20}{figure.2.7}\protected@file@percent }
\newlabel{fig:measurement_sample_rank_I_beamforming}{{2.7}{20}{Beamforming map, created with a rank I CSM created from measurement data}{figure.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Main Eigenvector}{20}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Noise Eigenvectors}{20}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Cross Spectral Matrix Snapshots}{20}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Data Augmentation}{20}{section.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Histograms of the values of the scalars of the eigenvectors with different index. The eigenvector with index $63$ is the main eigenvector (two last histograms).}}{21}{figure.2.8}\protected@file@percent }
\newlabel{fig:histograms_eigenvectors}{{2.8}{21}{Histograms of the values of the scalars of the eigenvectors with different index. The eigenvector with index $63$ is the main eigenvector (two last histograms)}{figure.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Full structure of the used implementation of the WGAN-GP to generate eigenvectors.}}{22}{figure.2.9}\protected@file@percent }
\newlabel{fig:flowchart_evecs_wgangp}{{2.9}{22}{Full structure of the used implementation of the WGAN-GP to generate eigenvectors}{figure.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Parameters}{22}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Results}{23}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Generating Eigenvalues from their Scaled Values}{23}{section.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The loss functions of the critic of the WGAN-GP for eigenvalues generation, respectively while performing the initial training and while fine-tuning}}{23}{figure.3.1}\protected@file@percent }
\newlabel{fig:loss_evals_wgangp}{{3.1}{23}{The loss functions of the critic of the WGAN-GP for eigenvalues generation, respectively while performing the initial training and while fine-tuning}{figure.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The first graph shows eigenvalues of a synthetic CSM (green), eigenvalues of a measured CSM (red), eigenvalues generated with the WGAN-GP for scaled eigenvalues after the initial training (blue) and eigenvalues generated with the WGAN-GP for scaled eigenvalues after the fine-tuning (orange). The second graph displays the levels of the same eigenvalues.}}{24}{figure.3.2}\protected@file@percent }
\newlabel{fig:samples_evals_wgangp}{{3.2}{24}{The first graph shows eigenvalues of a synthetic CSM (green), eigenvalues of a measured CSM (red), eigenvalues generated with the WGAN-GP for scaled eigenvalues after the initial training (blue) and eigenvalues generated with the WGAN-GP for scaled eigenvalues after the fine-tuning (orange). The second graph displays the levels of the same eigenvalues}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The loss functions of the critic of the WGAN-GP for the levels of eigenvalues generation, respectively while performing the initial training and while fine-tuning}}{24}{figure.3.3}\protected@file@percent }
\newlabel{fig:loss_evals_dB_wgangp}{{3.3}{24}{The loss functions of the critic of the WGAN-GP for the levels of eigenvalues generation, respectively while performing the initial training and while fine-tuning}{figure.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Generating Eigenvalues from their Level Values}{24}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The first graph shows eigenvalues of a synthetic CSM (green), eigenvalues of a measured CSM (red), eigenvalues generated with the WGAN-GP for level of eigenvalues after the initial training (blue) and eigenvalues generated with the WGAN-GP for level of eigenvalues after the fine-tuning (orange). The second graph displays the levels of the same eigenvalues.}}{25}{figure.3.4}\protected@file@percent }
\newlabel{fig:samples_evals_dB_wgangp}{{3.4}{25}{The first graph shows eigenvalues of a synthetic CSM (green), eigenvalues of a measured CSM (red), eigenvalues generated with the WGAN-GP for level of eigenvalues after the initial training (blue) and eigenvalues generated with the WGAN-GP for level of eigenvalues after the fine-tuning (orange). The second graph displays the levels of the same eigenvalues}{figure.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The loss functions of the critic of the WGAN-GP for the main eigenvector generation, respectively while performing the initial training and while fine-tuning}}{25}{figure.3.5}\protected@file@percent }
\newlabel{fig:loss_main_evec_wgangp}{{3.5}{25}{The loss functions of the critic of the WGAN-GP for the main eigenvector generation, respectively while performing the initial training and while fine-tuning}{figure.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Generating the Main Eigenvector}{25}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces The first beamforming map has been perfomed with a Rank I CSM computed with a generated main eigenvector. The second map shows the difference between the beamforming map obtained with Rank I CSM computed respectively with a generated main eigenvector and a main eigenvector from the dataset.}}{26}{figure.3.6}\protected@file@percent }
\newlabel{fig:beamforming_map_main_evec_wgangp}{{3.6}{26}{The first beamforming map has been perfomed with a Rank I CSM computed with a generated main eigenvector. The second map shows the difference between the beamforming map obtained with Rank I CSM computed respectively with a generated main eigenvector and a main eigenvector from the dataset}{figure.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Generating All the Eigenvectors}{26}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Generating the Snapshots}{26}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Data Augmentation}{26}{section.3.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces The first beamforming map has been perfomed with a CSM computed with the data augemntation scheme. The second map shwos the difference between the beamforming map obtained with CSM from respectively the data augmentation dataset and the training dataset}}{27}{figure.3.7}\protected@file@percent }
\newlabel{fig:beamforming_map_data_augmentation}{{3.7}{27}{The first beamforming map has been perfomed with a CSM computed with the data augemntation scheme. The second map shwos the difference between the beamforming map obtained with CSM from respectively the data augmentation dataset and the training dataset}{figure.3.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Discussions}{28}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Generating Eigenvalues from their Scaled Values}{28}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Generating Eigenvalues from their Level Values}{28}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Generating the Main Eigenvector}{28}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Generating All the Eigenvectors}{29}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Generating the Snapshots}{29}{section.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Data Augmentation}{29}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}General}{29}{section.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Future Works}{31}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{32}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Architectures of the Different Networks}{33}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate eigenvalues. Total params: 756,288, Trainable params: 755,776, Non-trainable params: 512}}{33}{table.A.1}\protected@file@percent }
\newlabel{tab:evals_generator_WGANGP_architecture}{{A.1}{33}{Architecture of the generator used in the WGAN-GP to generate eigenvalues. Total params: 756,288, Trainable params: 755,776, Non-trainable params: 512}{table.A.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate eigenvalues. Total params: 164,865, Trainable params: 164,865, Non-trainable params: 0}}{34}{table.A.2}\protected@file@percent }
\newlabel{tab:evals_critic_WGANGP_architecture}{{A.2}{34}{Architecture of the critic used in the WGAN-GP to generate eigenvalues. Total params: 164,865, Trainable params: 164,865, Non-trainable params: 0}{table.A.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate eigenvalues from their level values. Total params: 756,288, Trainable params: 755,776, Non-trainable params: 512}}{34}{table.A.3}\protected@file@percent }
\newlabel{tab:evals_dB_generator_WGANGP_architecture}{{A.3}{34}{Architecture of the generator used in the WGAN-GP to generate eigenvalues from their level values. Total params: 756,288, Trainable params: 755,776, Non-trainable params: 512}{table.A.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate eigenvalues from their level values. Total params: 164,865, Trainable params: 164,865, Non-trainable params: 0}}{34}{table.A.4}\protected@file@percent }
\newlabel{tab:evals_dB_critic_WGANGP_architecture}{{A.4}{34}{Architecture of the critic used in the WGAN-GP to generate eigenvalues from their level values. Total params: 164,865, Trainable params: 164,865, Non-trainable params: 0}{table.A.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.5}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate the main eigenvector. Total params: 821,888, Trainable params: 821,376, Non-trainable params: 512}}{35}{table.A.5}\protected@file@percent }
\newlabel{tab:main_evec_generator_WGANGP_architecture}{{A.5}{35}{Architecture of the generator used in the WGAN-GP to generate the main eigenvector. Total params: 821,888, Trainable params: 821,376, Non-trainable params: 512}{table.A.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.6}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate the main eigenvector. Total params: 197,633, Trainable params: 197,633, Non-trainable params: 0}}{35}{table.A.6}\protected@file@percent }
\newlabel{tab:main_evec_critic_WGANGP_architecture}{{A.6}{35}{Architecture of the critic used in the WGAN-GP to generate the main eigenvector. Total params: 197,633, Trainable params: 197,633, Non-trainable params: 0}{table.A.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.7}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate the noise eigenvectors. Total params: 37,520,384, Trainable params: 37,519,872, Non-trainable params: 512}}{35}{table.A.7}\protected@file@percent }
\newlabel{tab:noise_evecs_generator_WGANGP_architecture}{{A.7}{35}{Architecture of the generator used in the WGAN-GP to generate the noise eigenvectors. Total params: 37,520,384, Trainable params: 37,519,872, Non-trainable params: 512}{table.A.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.8}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate the noise eigenvectors. Total params: 35,263,489, Trainable params: 35,263,489, Non-trainable params: 0}}{36}{table.A.8}\protected@file@percent }
\newlabel{tab:noise_evecs_critic_WGANGP_architecture}{{A.8}{36}{Architecture of the critic used in the WGAN-GP to generate the noise eigenvectors. Total params: 35,263,489, Trainable params: 35,263,489, Non-trainable params: 0}{table.A.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.9}{\ignorespaces Architecture of the generator used in the WGAN-GP to generate snapshots used for creating an approximated CSM. Total params: 986,632, Trainable params: 977,796, Non-trainable params: 8,836}}{36}{table.A.9}\protected@file@percent }
\newlabel{tab:snapshots_generator_WGANGP_architecture}{{A.9}{36}{Architecture of the generator used in the WGAN-GP to generate snapshots used for creating an approximated CSM. Total params: 986,632, Trainable params: 977,796, Non-trainable params: 8,836}{table.A.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.10}{\ignorespaces Architecture of the critic used in the WGAN-GP to generate snapshots used for creating an approximated CSM. Total params: 4,317,761, Trainable params: 4,317,761, Non-trainable params: 0}}{37}{table.A.10}\protected@file@percent }
\newlabel{tab:snapshots_critic_WGANGP_architecture}{{A.10}{37}{Architecture of the critic used in the WGAN-GP to generate snapshots used for creating an approximated CSM. Total params: 4,317,761, Trainable params: 4,317,761, Non-trainable params: 0}{table.A.10}{}}
\bibstyle{IEEEtran}
\bibdata{./resources/IEEEabrv,./bibliography}
\bibcite{merino2019review}{1}
\bibcite{gerstoft2016multisnapshot}{2}
\bibcite{ronneberger2015u}{3}
\bibcite{grumiaux2022survey}{4}
\bibcite{he2018deep}{5}
\bibcite{ferguson2018sound}{6}
\bibcite{chakrabarty2017broadband}{7}
\bibcite{perotin2018crnn}{8}
\bibcite{adavanne2018direction}{9}
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }Bibliography}{39}{section*.15}\protected@file@percent }
\bibcite{takeda2016sound}{10}
\bibcite{karras2017progressive}{11}
\bibcite{neekhara2019expediting}{12}
\bibcite{NEURIPS2019_6804c9bc}{13}
\bibcite{engel2019gansynth}{14}
\bibcite{vargas2021improved}{15}
\bibcite{papayiannis2019data}{16}
\bibcite{ratnarajah2021fast}{17}
\bibcite{bianco2020semi}{18}
\bibcite{gerstoft2020parametric}{19}
\bibcite{hubner2021efficient}{20}
\bibcite{vera2021acoustic}{21}
\bibcite{welch1967use}{22}
\bibcite{sarradj2010fast}{23}
\bibcite{sarradj2012three}{24}
\bibcite{goodfellow2020generative}{25}
\bibcite{radford2015unsupervised}{26}
\bibcite{arjovsky2017wasserstein}{27}
\bibcite{DBLP:journals/corr/GulrajaniAADC17}{28}
\bibcite{castellini2021neural}{29}
\bibcite{lee2021deep}{30}
\bibcite{ma2019phased}{31}
\bibcite{xu2021deep}{32}
\bibcite{kujawski2022fast}{33}
\bibcite{gerstoft2012eigenvalues}{34}
\bibcite{nain2020wgangp}{35}
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }List of Figures}{43}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\hbox to\@tempdima {\hfil }List of Tables}{45}{section*.19}\protected@file@percent }
\gdef \@abspage@last{53}
