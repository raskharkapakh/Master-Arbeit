\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{cite}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{
    a4paper,
    total={170mm, 257mm},
    left=20mm,
    top=10mm,
}

\title{Master Thesis}
\author{Gaspard Ulysse Fragni√®re}
\date{August 2022}

\begin{document}

\maketitle

\section{How to \LaTeX}

How to make a reference to a paper:\cite{grumiaux2022survey}


\section{Draft}

\subsection{Grumiaux}


\cite{grumiaux2022survey} is a survey of several methods for sound source localization (SSL). Tradiontionally, this problem has been tackled using Signal Processing based methods. But in the recent years, methods based on deep learning have been developped and showed better results than traditional approaches. Those methods have been compiled in this paper. The survey is organized in the different following sections:

\begin{itemize}
    \item \textbf{Section I}: Introduction
    \item \textbf{Section II}: Acoustic Environment and Sound Source Configuration
    \item \textbf{Section III}: Conventional SSL methods
    \item \textbf{Section IV}: Neural Network Architectures for SSL
    \item \textbf{Section V}: Input Features
    \item \textbf{Section VI}: Outputs strategies
    \item \textbf{Section VII}: Data
    \begin{enumerate}
        \item Synthetic Data
        \item Real data
        \item Data augmentation techniques
    \end{enumerate}    
        
    \item \textbf{Section VIII}: Learning Strategies
    \item \textbf{Section IX}: Conclusions and Perspectives
    
\end{itemize}

We are interested in the section about Synthetic Data and Data augmentation. Indeed those sections can be used as a statring point for building the state of the art.Its goal is to answer the following questions:


\begin{itemize}
    \item Are there \textbf{existing methods} to generate virtually:
    \begin{itemize}
        \item measured time data (single channel/multi-channel)?
        \item measured source spectra (single channel/multi-channel)?
        \item measured cross-spectral matrices in stationary environments (multi-channel only)?
        
    \end{itemize}
    \item What \textbf{measurement scenarios} are used in the literature (time-stationary/non-stationary sources, number of microphones, temporal dimensions... )?
    \item What are the \textbf{existing setups} in multi-channel data generation with neural networks (conditioning variables, network architectures (convolutional, recurrent, Transformer,\dots), generative algorithms (GAN/VAE), \dots)
\end{itemize}

In \cite{grumiaux2022survey}, a classical method about data generation is introduced. The idea is the following: Simulate the Room Impulse Response (RIR) in order to simulate realistically room acoustics (e.g. reverberation). Then convolve dry audio signals with the RIR simulated. This can provide suited training data, since RIR for rooms of different size, different source prosition as well as different dry signals can be used for the training.

In  \cite{deleforge2015co}, the datasets is created in the following way: a speaker with a visual marker is placed in front of camera and binaural microphone setup (dummy head). "The loud-speaker that emits fixed-length full-spectrum sounds is moved in front of the dummy-head/camera device and for each loud-speaker location, both the emitted sound and the image location of the visual marker are recorded. $\rightarrow$ not so useful

In \cite{vargas2021improved}, a GAN is used to simulate data. The GAN used in \cite{vargas2021improved} is an implementation of \cite{neekhara2019expediting}

\cite{hubner2021efficient} proposed a low-complexity model-based training data generation method that includes a deterministic model for the direct path and a statistical model for late reverberation. It has been demonstrated that the SSL neural network, trained using the data generated by this method, achieves comparable localization performance as the same architecture trained on a dataset generated by the usual ISM.

An investigation of several simulation methods was done by \cite{gelderblom2021synthetic}, with extensions of ISM, namely, ISM with directional sources, and ISM with a diffuse field due to scattering. \cite{gelderblom2021synthetic} compared the simulation algorithms via the training of an MLP (in both regression and classification modes) and showed that ISM with scattering effects and directional sources leads to the best SSL performance.

\cite{neekhara2019expediting} : We propose a learning-based method which uses Generative Adversarial Networks [12] to learn a stochastic mapping from perceptually-informed spectrograms into simple magnitude spectrograms.

Paper read and not useful:

\begin{itemize}
    \item Deleforge 2013 \cite{deleforge2013variational}
    \item 
\end{itemize}

\subsection{Bianco}

In Bianco a VAE is used to perform SSL. The idea is the following: based on VAEs to encode the phase of the relative transfer function (RTF) between two microphones to a latent parametric distribution. The resulting model estimates DOA and generates RTF phase.

VAEs learn from unlabeled data explicit latent codes for generating samples, and are
inspiring examples of representation learning. 

There is a link between DOA and RTF. Indeed, the RTF phase is encoded as a function of source azimuth (direction of arrival, DOA). Similarly as in \cite{gerstoft2020parametric}, the goal of the NN (GAN or VAE) is to learn the distribution of a a quantity that is a function of the DOA. 

The experiments show, only \textbf{two labeled samples per DOA} permit the VAE-SSL to obtain better performance than SRP-PHAT (State of the art).

\begin{itemize}
    \item \textbf{in:} 
    \item \textbf{out:} Relative Transfer Function (RTF)
\end{itemize}
what is RTF: TODO: continue

\subsection{Neekhara}

\cite{neekhara2019expediting} is concerned with finding a solution for Text to speech (TTS) problem. The claim is that using a GAN approach, they have been able to outperform by far naive approaches (user review) and being 100x faster than other DL approaches. More specifically this paper was concerned with creating a mapping from language to \textbf{perceptually informed spectogram}. Indeed the difficluty of the problem lays in the fact that perceptually informed spectograms are not invertible. Indeed a spectogram is a compact representation of a signal where much of the information contained in a audio waveform has been lost. More specifically the problem at hand is phase estimation and magnitude estimation. Therefore a predictive model is required to fill the missing information and create natural sounding sound.

\begin{itemize}
    \item \textbf{in:} (perceptually informed) spectogram (or text on a more basic level)
    \item \textbf{out:} natural sounding audio waveform
\end{itemize}

\subsection{NEURIPS}

\cite{NEURIPS2019_6804c9bc} also introduces a method for the TTS problem. Moreover in the introduction of the paper, there is a comparison of different method for text to speech (i.e. audio wave generation):

\begin{itemize}
    \item \textbf{Pure signal processing approaches:} "The main issue with these pure signal processing methods is that the mapping from intermediate features to audio usually \textbf{introduces noticeable artifacts}"
    \item \textbf{Autoregressive NN based models:} An autoregressive model is a model that relies on past values to predict current ones. In this sense, an autoregressive model must be sequential. "These methods have produced state-of-the-art results in text-to-speech synthesis and other audio generation tasks. Unfortunately, inference with these models is inherently slow and inefficient because audio samples must be generated sequentially. Thus auto-regressive models are \textbf{usually not suited for real-time applications}."

    \item \textbf{Non autoregressive models:} "While inference is fast on the GPU, the large size of the model makes it \textbf{ impractical for applications with a constrained memory budget.}"
    \item \textbf{GAN for audio:} However their results show that adversarial loss alone is not sufficient for high quality waveform generation; it requires a  KL-divergence based distillation objective as a critical component. To this date, making them work well in this domain has been challenging
\end{itemize}

In \cite{NEURIPS2019_6804c9bc}, a GAN (MelGAN) is introduced. The goal of this GAN is to perform audio waveform generation.

\begin{itemize}
    \item \textbf{in:} mel-spectogram 
    \item \textbf{out:} audio waveform
\end{itemize}

\subsection{EngelGanSynth:}

\cite{engel2019gansynth} is concerned with demonstrating that GANs can in fact generate high-fidelity and locally-coherent naudio by modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain.

Using a GAN approach and the NSythn datasets (Dataset of standardized notes from instrument) to generate notes. 

TODO: According to Adam, this paper is to generate spectogram and not audio wave form. $\rightarrow$ check again
\begin{itemize}

    \item \textbf{in:} instruments note from datasets NSynth 
    \item \textbf{out:} instruments audio waveform.
\end{itemize}

\subsection{gerstoft}

\cite{gerstoft2020parametric} is concerned with training a GAN for generating audio based features. 

In many array processing techniques (i.e. beamfroming) first compute the Sample Covariance Matrix (SCM). The idea of the (Wasserstein) GAN here is to generate many SCM. More specifically, the goal of the GAN is to learn the \textbf{joint} probability distribution function of the \textbf{observable data} (array data) and the \textbf{target variable} (Wasserstein distance). The wasserstein distance is a metric to measure distance between probability distribution on a given metric space.

The idea is first to consider a model that describe relationship between \textbf{array data} and \textbf{DOA}. Using this model, another relationship betwen \textbf{CSM} and \textbf{array data} can be defined. Hence we have a mathematical relationship between \textbf{DOA} and \textbf{CSM}.

\begin{itemize}
    \item \textbf{in:} True Sample Covariance Matrix with DOA
    \item \textbf{out:} Generator, i.e. probability distribution function
\end{itemize}

Idea: maybe it would be possible to generate for the pdf os SCM for several DOA. Moreover, a link between SCM and cross spectral matrix should be investigated.

\subsection{Vera-Diaz}

In ASL prblem, the source‚Äôs position can be estimated with at least three Time Difference of Arrival (TDoA) measurements with hyperbolic trilateration methods. Signals captured in everyday scenarios are contaminated with noise and multipath effects.
Directly measuring TDoA in those cases is a diÔ¨Écult task that produces inaccurate localization results.\cite{vera2021acoustic} is concerned with finding a way to denoise those signals. Other methods uses GCC instead of TDoA. SUch methods are more robust to noise and multipath effects, but not fully immune to it. 

The contribution of this paper is a DNN named DeepGCC. This DNN takes as input a GCC(Generalized Cross Correlation) Matrix and estimates a Gaussian function. Then the SSL problem is solved by replacing the GCC typically used by DeepGCC(GCC) and then using a classical beamforming approach. 

\begin{itemize}
    \item \textbf{in:} GCC
    \item \textbf{out:} (x,y,z)
\end{itemize}

$\rightarrow$ this is actually the inverse of what we want. Hence if we could reverse this nectwork, maybe we could do something of the following: 

\begin{equation}
    (x,y,z) \rightarrow GCC \rightarrow CSM
\end{equation}

Where the last step is done thanks to the relation between $GCC$ and $CSM$ via Fourier transform. 


\subsection{H√ºbner}

This paper is concerned with dealing with a common issue when creating DL algorithm to solve the SSL problem, namely the complexity to gather data for training/validating. Indeed, the two current way to obtain data is by either generating them using simulation or by recording them in real life. Both methods require significant amount of resources (resp. time or storage)

\textbf{TODO}: Use those quotes to structure a bit the the state-of-the-art

quotes from H√ºbner:
2
"DOA estimation methods can be categorized into classical model-based methods and data-driven methods, which are prevalently implemented using deep neural networks (DNN)."

"Most of the DL methods include a feature extraction step rather than using the raw microphone signals. Popular features include:

\begin{itemize}
    \item (i) the eigendecomposition of the spatial covariance matrix [14] (similar to MUSIC)
    \item (ii) generalized cross-correlation (GCC) based features [15‚Äì18]
    \item (iii) modal coherence [19]
    \item (iv) the Ambisonics intensity vectors [20]
    \item (v) phase and magnitude spectra [21] and
    \item (vi) phase spectra [11, 12]. Many of the features are phase-based as motivated by physical models and classical DOA estimators [9].
\end{itemize}
"

"One way to generate training data for DL-based DOA estimation is by recording sound emitted from a source (e.g., loudspeaker, human) in real acoustic environments [16, 17]. This approach is time-consuming and for high-quality datasets a precise ground truth position is essential, which requires expensive measurement equipment."

"Another popular method is the convolution of signals (e.g., speech) with room impulse responses (RIRs) that have either been recorded [14, 18] or simulated based on the source-image method [11, 12, 20, 21, 23]. The main drawbacks of these data generation methods are excessive time and storage consumption."


Conclusion: 
"We proposed a low complexity model-based training data
generation method for phase-based DOA estimation. The
proposed method models the microphone phases directly
in the frequency domain to avoid computationally costly
operations as present in state-of-the-art methods. The low
computational complexity of the proposed method allows for
online training data generation, which allows faster proto-
typing, and paves the way for \textbf{applications with a high data
demand} such as moving sound sources simulation or large
microphone arrays. An evaluation using measured RTFs
yielded \textbf{comparable results} for phase-based DOA estimation
when using \textbf{the proposed method and the computationally
expensive source-image method for training data generation.}"

\subsection{Difference between VAE and GAN}

In the context of image generation:

"GANs generally produce better photo-realistic images but can be difficult to work with. Conversely, VAEs are easier to train but don‚Äôt usually give the best results.

I recommend picking VAEs if you don‚Äôt have a lot of time to experiment with GANs and photorealism isn‚Äôt paramount.

There are exceptions such as Google‚Äôs VQ-VAE 2 which can compete with GANs for image quality and realism. There is also VAE-GAN and VQ-VAE-GAN.

As a note, GANs and VAEs are not specifically for images and can be used for other data types/structures." (this is from a comment on stackstats -> not really usable as a source).

TODO: $\rightarrow$ read \cite{10.1007/978-3-030-38961-1_8}


% =======================================================================================

\section{Goal}

The goal of the project is to create a GAN to generate either:
\begin{itemize}
    \item cross-spectral matrix
    \item the complex-valued sound pressure vector at the different microphone
\end{itemize}
with the corresponding labels (DoA).

In some way the goal of this project is to create a GAN to realistically add noise to either a cross spectral matrix or complex-valued signal sound pressure vector of an array of microphone. This noise pdf should be estimated instead of being modelled. Indeed a GAN approach is necessary to reduce the computation time and the storage required. Indeed we want to be able to generate randomly and in real time labeled data.  


\section{Important words}

\begin{itemize}
    \item SSL: Sound source localization
    \item alternatively SSL: Semi-Supervised Learning
    \item ASL: Acoustics Source Localization    
    \item Source Spectra
    \item GCC: Generalized Cross Correlation
    \item CSM: Cross Spectral Matrix (note that there is a connection between the CSM and the GCC features via the Fourier transform)
    \item SCM: Sample Covariance Matrix
    \item CB map: Conventional Beamforming map (also known as Acoustic Power Map???)
\end{itemize}

\section{State-of-the-art}

The problem of Sound Source Localization (SSL) is typically dealt with with two approaches: Model-based and Data-driven. The issue that we try to adress is that for data driven approaches, significant quantities of well structures data are required. In the litterature, two main ways of obtaining data have been observed:

\begin{itemize}
    \item Record sound emitted with a loudspeaker or human voice in a real acoustic enviromnent. The issue with such methods is that it can be very tedious te record in different environment. Moreover, recording sufficiently data is very time consuming. Finally, to build a high quality data sets, expensive equipment is required to have an accurate groundtruth. \textbf{TODO: add reference}
    \item Simulate a Room Impulse Response (RIR) in order to recreate realistic room acoustics (e.g. reverberation). Then convolve dry audio signals with the RIR simulated. This can provide suited training data, since RIR for rooms of different size, different source prosition as well as different dry signals can be used for the training. The issue with such a method is the important amount of time and data required. \textbf{TODO: add reference}
\end{itemize}


Therefore we would like to find another to generate datas. But before tackling this problem, it is important to note that DL-based approach do not use raw data (direct recording of microphone input) but instead features extracted from the raw data. This is crucial because it means that recording or simulating raw microphone data is no longer necessary, if good quality features could be generated directly. The features that are typically used in DL approaches are:

\begin{enumerate}
    \item Generalized Cross-Correlation (GCC) based features \textbf{TODO: add reference+ check}
    \item Eigendecomposition of the Spatial Covariance Matrix \textbf{TODO: add reference+ check}
    \item Modal coherence \textbf{TODO: add reference+ check}
    \item Ambisonics intensity vectors \textbf{TODO: add reference+ check}
    \item Phase and Magnitude Spectra \textbf{TODO: add reference+ check}
    \item Phase Spectra \textbf{TODO: add reference+ check}
\end{enumerate}

% Bibliography
%\addbibresource{mybib.bib}
\bibliography{mybib}
\bibliographystyle{plain} 


\end{document}
