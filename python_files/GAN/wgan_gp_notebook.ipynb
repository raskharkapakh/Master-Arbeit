{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 15:37:54.292209: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 15:37:54.518208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-29 15:37:54.518244: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-29 15:37:54.550798: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-29 15:37:55.475188: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-29 15:37:55.475273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-29 15:37:55.475281: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from wgan_gp import WGAN_GP\n",
    "from load_dataset import parser, full_parser\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gaspard/anaconda3/envs/master_arbeit/lib/python3.10/site-packages/keras/layers/normalization/batch_normalization.py:562: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 15:37:57.570757: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-29 15:37:57.570801: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-29 15:37:57.570822: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gaspard-HP-ZBook-15u-G2): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 16)        592       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " zero_padding2d (ZeroPadding  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 17, 17, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 17, 17, 32)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 17, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 9, 9, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 9, 9, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10368)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 10369     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,849\n",
      "Trainable params: 108,401\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 32768)             4227072   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 32, 32, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 128)       262272    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 64)        131136    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 4)         4100      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 64, 64, 4)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,625,348\n",
      "Trainable params: 4,624,964\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "real_sample shape (None, 64, 64, 4)\n",
      "fake_sample shape (None, 64, 64, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert a partially known TensorShape (None, 64, 64, 4) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gaspard/ETHZ/Master_Arbeit/repo/Master-Arbeit/python_files/GAN/wgan_gp_notebook.ipynb Cellule 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gaspard/ETHZ/Master_Arbeit/repo/Master-Arbeit/python_files/GAN/wgan_gp_notebook.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Creating GAN\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gaspard/ETHZ/Master_Arbeit/repo/Master-Arbeit/python_files/GAN/wgan_gp_notebook.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m wgan_gp \u001b[39m=\u001b[39m WGAN_GP()\n",
      "File \u001b[0;32m~/ETHZ/Master_Arbeit/repo/Master-Arbeit/python_files/GAN/wgan_gp.py:133\u001b[0m, in \u001b[0;36mWGAN_GP.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreal_sample shape \u001b[39m\u001b[39m{\u001b[39;00mreal_sample\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfake_sample shape \u001b[39m\u001b[39m{\u001b[39;00mfake_sample\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m interpolated_sample \u001b[39m=\u001b[39m RandomWeightedAverage()([real_sample, fake_sample])\n\u001b[1;32m    134\u001b[0m \u001b[39m# Determine validity of weighted sample\u001b[39;00m\n\u001b[1;32m    135\u001b[0m validity_interpolated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic(interpolated_sample)\n",
      "File \u001b[0;32m~/anaconda3/envs/master_arbeit/lib/python3.10/site-packages/keras/engine/base_layer_v1.py:838\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    835\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    836\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m    837\u001b[0m     ):\n\u001b[0;32m--> 838\u001b[0m         outputs \u001b[39m=\u001b[39m call_fn(cast_inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    840\u001b[0m \u001b[39mexcept\u001b[39;00m tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mOperatorNotAllowedInGraphError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    841\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are attempting to use Python control \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mflow in a layer that was not declared to be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    848\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master_arbeit/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/master_arbeit/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/master_arbeit/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/master_arbeit/lib/python3.10/site-packages/keras/layers/merging/base_merge.py:196\u001b[0m, in \u001b[0;36m_Merge.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[39mreturn\u001b[39;00m y\n\u001b[1;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_function(inputs)\n",
      "File \u001b[0;32m~/ETHZ/Master_Arbeit/repo/Master-Arbeit/python_files/GAN/wgan_gp.py:77\u001b[0m, in \u001b[0;36mRandomWeightedAverage._merge_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_merge_function\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[1;32m     75\u001b[0m     \u001b[39m#alpha = K.random_uniform((32, 1, 1, 1))\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     shape \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> 77\u001b[0m     alpha \u001b[39m=\u001b[39m K\u001b[39m.\u001b[39;49mrandom_uniform(shape)\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m (alpha \u001b[39m*\u001b[39m inputs[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m ((\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m alpha) \u001b[39m*\u001b[39m inputs[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/master_arbeit/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/master_arbeit/lib/python3.10/site-packages/keras/backend.py:6832\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m   6830\u001b[0m \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6831\u001b[0m     seed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m10e6\u001b[39m)\n\u001b[0;32m-> 6832\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49muniform(\n\u001b[1;32m   6833\u001b[0m     shape, minval\u001b[39m=\u001b[39;49mminval, maxval\u001b[39m=\u001b[39;49mmaxval, dtype\u001b[39m=\u001b[39;49mdtype, seed\u001b[39m=\u001b[39;49mseed\n\u001b[1;32m   6834\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert a partially known TensorShape (None, 64, 64, 4) to a Tensor."
     ]
    }
   ],
   "source": [
    "# Creating GAN\n",
    "wgan_gp = WGAN_GP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "tfile = \"/home/gaspard/ETHZ/Master_Arbeit/acoupipe_datasets/training_1-100000_csmtriu_1src_he4.0625-1393.4375Hz_ds1-v001_13-Sep-2022.tfrecord\"\n",
    "dataset = tf.data.TFRecordDataset(filenames=[tfile])\n",
    "\n",
    "# The parser convert the CSMTRIU into eigenvector (TODO: need to be extended to also extract the eigenvalues.)\n",
    "dataset = dataset.map(full_parser)\n",
    "#dataset = dataset.map(parser)\n",
    "\n",
    "#  Creating the batches\n",
    "dataset = dataset.shuffle(buffer_size=10).batch(wgan_gp.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the GAN\n",
    "wgan_gp.train(n_epochs=1245\n",
    ", dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup wgan_gp\n",
    "file_to_store = open(\"backup_wgan_gp.pickle\", \"wb\")\n",
    "pickle.dump(wgan_gp, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wgan from backup\n",
    "file_to_read = open(\"backup_wgan_gp.pickle\", \"rb\")\n",
    "generated_backup = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generating a sample:\n",
    "generated = wgan_gp.get_sample()\n",
    "\n",
    "if generated != None:\n",
    "    evecs_r = generated[0,:,:,0]\n",
    "    evecs_i = generated[0,:,:,1]\n",
    "    evals_r = generated[0,:,:,2]\n",
    "    evals_i = generated[0,:,:,3]\n",
    "\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(evecs_r)\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(evecs_i)\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(evals_r)\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.imshow(evals_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup of generated sample\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "file_to_store = open(\"backup_generated.pickle\", \"wb\")\n",
    "pickle.dump(generated, file_to_store)\n",
    "file_to_store.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restauring file from backup\n",
    "file_to_read = open(\"backup_generated.pickle\", \"rb\")\n",
    "generated_backup = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beamforming import beamform\n",
    "\n",
    "beamform(generated_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan_gp_copied_pasted import WGANGP\n",
    "\n",
    "wgan = WGANGP()\n",
    "wgan.train(epochs=30000, batch_size=32, sample_interval=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import add, concatenate\n",
    "\n",
    "print(dir(concatenate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('master_arbeit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d46cea35c42c054183b6642d4f981f16f79b8ccebc5e48374ba9e6e0f8016689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
